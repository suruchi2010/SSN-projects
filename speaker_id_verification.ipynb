{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suruchi2010/SSN-projects/blob/main/speaker_id_verification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf8iC_Pj2pN-",
        "outputId": "13e1a551-d659-4bdf-9294-1a4f3232b969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=3221c397be1efa63fd946a7ed506606ac04e049076d02584cc1b51502555adea\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ]
        }
      ],
      "source": [
        "!pip3 install python_speech_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHcvOkAI3OmI"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn import preprocessing\n",
        "from scipy.io.wavfile import read\n",
        "from python_speech_features import mfcc\n",
        "from python_speech_features import delta\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dg-2-uhExmJ",
        "outputId": "a20a580a-b9df-49f5-e327-2ba9f0cc62c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/speaker id/testing/kavitha',\n",
              " '/content/gdrive/My Drive/speaker id/testing/madhu',\n",
              " '/content/gdrive/My Drive/speaker id/testing/suruchi']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from glob import glob \n",
        "#glob()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "\n",
        "path = \"/content/gdrive/My Drive/speaker id\"\n",
        "audio_files= glob(path + '/*')\n",
        "audio_test=glob(audio_files[1] + '/*')\n",
        "audio_train=glob(audio_files[0] + '/*')\n",
        "\n",
        "#audio_train\n",
        "audio_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7FWkA_9FWvM"
      },
      "outputs": [],
      "source": [
        "class feature_ext:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "       \n",
        "    def extract_features(self, audio_path):\n",
        "        \t\n",
        "        \n",
        "        data, audio  = read(audio_path)\n",
        "        print(data)\n",
        "        mfcc_feature = mfcc(\n",
        "                            audio,\n",
        "                            # This displays the sampling rate we are looking for\n",
        "                            data,\n",
        "                            \n",
        "                            winlen       = 0.05, #the length of the analysis window in seconds.\n",
        "                            \n",
        "                            winstep      = 0.01, #the step between successive windows in seconds\n",
        "                            \n",
        "                            numcep       = 13, #the number of cepstrum to return\n",
        "                            \n",
        "                            nfilt        = 30, #the number of filters in the filterbank\n",
        "                            \n",
        "                            nfft         = 1024, # the FFT size\n",
        "                           \n",
        "                            appendEnergy = True) #if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
        "    \n",
        "        \n",
        "        mfcc_feature  = preprocessing.scale(mfcc_feature)\n",
        "        deltas        = delta(mfcc_feature, 2)\n",
        "        double_deltas = delta(deltas, 2)\n",
        "        combined      = np.hstack((mfcc_feature, deltas, double_deltas))\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-jeyte3Rkf",
        "outputId": "caebb923-85c3-4e8d-b228-5b28e55bc9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/suruchi/suruchi_1.wav\n",
            "44100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:frame length (2205) is greater than FFT size (1024), frame will be truncated. Increase NFFT to avoid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/suruchi/suruchi_2.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/suruchi/suruchi_3.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/suruchi/suruchi_4 .wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/madhu/madhu_4.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/madhu/madhu_3.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/madhu/madhu_2.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/madhu/madhu_1.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/kavitha/kavitha_1.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/kavitha/kavitha_2.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/kavitha/kavitha_3.wav\n",
            "16000\n",
            "PROCESSNG  /content/gdrive/My Drive/speaker id/training/kavitha/kavitha_4.wav\n",
            "16000\n",
            "SAVING  madhu.gmm\n",
            "SAVING suruchi.gmm\n",
            "SAVING kavitha.gmm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class ModelsTrainer:\n",
        "\n",
        "    def __init__(self,madhu_file, suruchi_file, kavitha_file):\n",
        "        self.madhu_train   = madhu_file\n",
        "        self.suruchi_train = suruchi_file\n",
        "        self.kavitha_train  = kavitha_file\n",
        "        self.features_extractor    = feature_ext()\n",
        "\n",
        "    def process(self):\n",
        "        madhu,suruchi, kavitha = self.get_file_paths(self.madhu_train,\n",
        "                                             self.kavitha_train,\n",
        "                                             self.suruchi_train)\n",
        "        # collect voice features\n",
        "        voice_feat_madhu   = self.collect_features(madhu)\n",
        "        voice_feat_suruchi = self.collect_features(suruchi)\n",
        "        voice_feat_kavitha   = self.collect_features(kavitha)\n",
        "        \n",
        "        # generate gaussian mixture models\n",
        "        madhu_gmm   = GaussianMixture(n_components = 64, max_iter = 1000, covariance_type='full', n_init = 3)\n",
        "        suruchi_gmm = GaussianMixture(n_components = 64, max_iter = 1000, covariance_type='full', n_init = 3)\n",
        "        kavitha_gmm   = GaussianMixture(n_components = 64, max_iter = 1000, covariance_type='full', n_init = 3)\n",
        "        \n",
        "        # fit features to models\n",
        "        madhu_gmm.fit(voice_feat_madhu)\n",
        "        suruchi_gmm.fit(voice_feat_suruchi)\n",
        "        kavitha_gmm.fit(voice_feat_kavitha)\n",
        "        \n",
        "\n",
        "        # save models\n",
        "        self.save_gmm(madhu_gmm, \"madhu\")\n",
        "        self.save_gmm(suruchi_gmm, \"suruchi\")\n",
        "        self.save_gmm(kavitha_gmm, \"kavitha\")\n",
        "        \n",
        "\n",
        "    def get_file_paths(self, suruchi_train, kavitha_train, madhu_train):\n",
        "        # get file paths\n",
        "        madhu   = [ os.path.join(madhu_train, f) for f in os.listdir(madhu_train) ]\n",
        "        suruchi = [ os.path.join(suruchi_train, f) for f in os.listdir(suruchi_train) ]   \n",
        "        kavitha  = [ os.path.join(kavitha_train, f) for f in os.listdir(kavitha_train) ] \n",
        "        \n",
        "    \n",
        "        return madhu,suruchi, kavitha\n",
        "\n",
        "    def collect_features(self, files):\n",
        "        \n",
        "        features = np.asarray(())\n",
        "        # extract features for each speaker\n",
        "        for file in files:\n",
        "            print(\"%5s %10s\" % (\"PROCESSNG \", file))\n",
        "            # extract MFCC & delta MFCC features from audio\n",
        "            vector    = self.features_extractor.extract_features(file)\n",
        "            # stack the features\n",
        "            if features.size == 0: \n",
        "               features = vector\n",
        "            else:                \n",
        "                 features = np.vstack((features, vector))\n",
        "        return features\n",
        "\n",
        "    def save_gmm(self, gmm, name):\n",
        "        \n",
        "        filename = name + \".gmm\"\n",
        "        with open(filename, 'wb') as gmm_file:\n",
        "            pickle.dump(gmm, gmm_file)\n",
        "        print (\"%5s %10s\" % (\"SAVING\", filename,))\n",
        "\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "    models_trainer = ModelsTrainer(audio_train[0], audio_train[1],audio_train[2])\n",
        "    models_trainer.process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BorC1IqFMog_",
        "outputId": "3bb44b76-d73f-4252-bf4c-1cc6595454fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> TESTING        : madhu_cut5sec.wav\n",
            "16000\n",
            "+ MADHU SCORE     : -7.135\n",
            "+ SURUCHI SCORE     : -0.522\n",
            "+ KAVITHA SCORE     : -4.342\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 1\n",
            "----------------------------------------------------\n",
            "--> TESTING        : madhu_2.wav\n",
            "16000\n",
            "+ MADHU SCORE     : -5.399\n",
            "+ SURUCHI SCORE     : -1.91\n",
            "+ KAVITHA SCORE     : -6.07\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 1\n",
            "----------------------------------------------------\n",
            "--> TESTING        : suruchi_test2.wav\n",
            "16000\n",
            "+ MADHU SCORE     : -5.412\n",
            "+ SURUCHI SCORE     : -7.978\n",
            "+ KAVITHA SCORE     : -11.024\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 0\n",
            "----------------------------------------------------\n",
            "--> TESTING        : suruchi_test1.wav\n",
            "16000\n",
            "+ MADHU SCORE     : 10.188\n",
            "+ SURUCHI SCORE     : -3.346\n",
            "+ KAVITHA SCORE     : -3.567\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 0\n",
            "----------------------------------------------------\n",
            "--> TESTING        : kavitha _2.wav\n",
            "16000\n",
            "+ MADHU SCORE     : -8.886\n",
            "+ SURUCHI SCORE     : -5.197\n",
            "+ KAVITHA SCORE     : -0.974\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 2\n",
            "----------------------------------------------------\n",
            "--> TESTING        : kavitha_1.wav\n",
            "16000\n",
            "+ MADHU SCORE     : -5.718\n",
            "+ SURUCHI SCORE     : -1.722\n",
            "+ KAVITHA SCORE     : -0.059\n",
            "+ EXPECTATION      : conten\n",
            "+ IDENTIFICATION   : 2\n",
            "----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "class SpeakerIdentifier:\n",
        "\n",
        "    def __init__(self, speaker1_files_path, speaker2_files_path, speaker3_files_path,madhu_model_path, suruchi_model_path,kavitha_model_path):\n",
        "        self.speaker1_testing_path = speaker1_files_path\n",
        "        self.speaker2_testing_path = speaker2_files_path\n",
        "        self.speaker3_testing_path = speaker3_files_path\n",
        "        self.error                 = 0\n",
        "        self.total_sample          = 0\n",
        "        self.features_extractor   = feature_ext()\n",
        "        # load models\n",
        "        self.madhu_gmm   = pickle.load(open(madhu_model_path, 'rb'))\n",
        "        self.suruchi_gmm = pickle.load(open(suruchi_model_path, 'rb'))\n",
        "        self.kavitha_gmm   = pickle.load(open(kavitha_model_path, 'rb'))\n",
        "        \n",
        "\n",
        "\n",
        "    def process(self):\n",
        "        files = self.get_file_paths(self.speaker1_testing_path, self.speaker2_testing_path,self.speaker3_testing_path)\n",
        "        # read the test directory and get the list of test audio files\n",
        "        #print(files)\n",
        "        for file in files:\n",
        "            self.total_sample += 1\n",
        "            print(\"%10s %8s %1s\" % (\"--> TESTING\", \":\", os.path.basename(file)))\n",
        "\n",
        "            vector = self.features_extractor.extract_features(file)\n",
        "            winner = self.identify_speaker(vector)\n",
        "            #print(winner)\n",
        "            expected_speaker = file.split(\"/\")[1][:-1]\n",
        "            #print(expected_speaker)\n",
        "\n",
        "            print(\"%10s %6s %1s\" % (\"+ EXPECTATION\",\":\", expected_speaker))\n",
        "            print(\"%10s %3s %1s\" %  (\"+ IDENTIFICATION\", \":\", winner))\n",
        "\n",
        "            if winner != expected_speaker: self.error += 1\n",
        "            print(\"----------------------------------------------------\")\n",
        "            \n",
        "\n",
        "    def get_file_paths(self, speaker1_testing_path, speaker2_testing_path, speaker3_testing_path):\n",
        "        # get file paths\n",
        "\n",
        "        speaker1 = [ os.path.join(speaker1_testing_path, f) for f in os.listdir(speaker1_testing_path) ]\n",
        "        speaker2   = [ os.path.join(speaker2_testing_path, f) for f in os.listdir(speaker2_testing_path) ]\n",
        "        speaker3   = [ os.path.join(speaker3_testing_path, f) for f in os.listdir(speaker3_testing_path) ]\n",
        "        #speaker1 = speaker1_testing_path\n",
        "        #speaker2 = speaker2_testing_path\n",
        "        #speaker3 = speaker3_testing_path\n",
        "\n",
        "        files   = speaker1 + speaker2 + speaker3\n",
        "        return files\n",
        "\n",
        "    def identify_speaker(self, vector):\n",
        "\n",
        "        log_likelihood=[]\n",
        "\n",
        "        # madhu hypothesis scoring\n",
        "        is_madhu_scores         = np.array(self.madhu_gmm.score(vector))\n",
        "        is_madhu_log_likelihood = is_madhu_scores.sum()\n",
        "        log_likelihood.append(is_madhu_log_likelihood)\n",
        "        #print('l_l'.format(log_likelihood))\n",
        "\n",
        "        # suruchi hypothesis scoring\n",
        "        is_suruchi_scores         = np.array(self.suruchi_gmm.score(vector))\n",
        "        is_suruchi_log_likelihood = is_suruchi_scores.sum()\n",
        "        log_likelihood.append(is_suruchi_log_likelihood)\n",
        "        #print('l_l'.format(log_likelihood))\n",
        "\n",
        "        # kavitha hypothesis scoring\n",
        "        is_kavitha_scores         = np.array(self.kavitha_gmm.score(vector))\n",
        "        is_kavitha_log_likelihood = is_kavitha_scores.sum()\n",
        "        log_likelihood.append(is_kavitha_log_likelihood)\n",
        "        #print('l_l'.format(log_likelihood))\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "        print(\"%10s %5s %1s\" % (\"+ MADHU SCORE\",\":\", str(round(is_madhu_log_likelihood, 3))))\n",
        "        print(\"%10s %5s %1s\" % (\"+ SURUCHI SCORE\",\":\", str(round(is_suruchi_log_likelihood, 3))))\n",
        "        print(\"%10s %5s %1s\" % (\"+ KAVITHA SCORE\",\":\", str(round(is_kavitha_log_likelihood, 3))))\n",
        "       \n",
        "        winner = np.argmax(log_likelihood)\n",
        "        return winner\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "    speaker_identifier = SpeakerIdentifier(audio_test[1], audio_test[2], audio_test[0],\"madhu.gmm\",\"suruchi.gmm\", \"kavitha.gmm\")\n",
        "    speaker_identifier.process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HQufR8hnOXJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}